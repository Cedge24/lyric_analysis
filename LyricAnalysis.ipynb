{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8c814e8",
   "metadata": {},
   "source": [
    "# Song lyric collection and analysis with lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13b6097c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lyrics, tokenize by line, word tokenize, analysis\n",
    "# IDEAS : - filter out adlibs\n",
    "# -to check vocab size need to do : # unique words / total words\n",
    "# - need to lemmatize words before removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f96df01d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cedge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cedge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import lyricsgenius as lg\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e21e6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/Users/cedge/JupyterNotebooks/LyricAnalysis/data/auto_.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afaff24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "genius = lg.Genius('zleUnA417r4r6kLBco4G748hX7O43uBFJoOFF55Kv2K9YF1fnsKxTbXoIHpzg3fN', skip_non_songs=True,\n",
    "                   excluded_terms=[\"(Remix)\", \"(Live)\"],remove_section_headers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3679c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lyricsgenius to get song lyrics for input artist, return tokenized lyrics\n",
    "def get_artist_lyrics(artist, n):\n",
    "    i = 0\n",
    "    song_tokens = []\n",
    "    songs = (genius.search_artist(artist, max_songs=n, sort='popularity')).songs\n",
    "    s = [song.lyrics for song in songs]\n",
    "    for song in s:\n",
    "        lyrics = song[song.index('\\n')+1:]\n",
    "        tokes = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(lyrics)\n",
    "        tokes = [w.lower() for w in tokes if not w.lower() in nltk.corpus.stopwords.words()]\n",
    "        song_tokens.append(tokes)\n",
    "    return song_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11f486a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same function but lemmatizing words\n",
    "def get_artist_lyrics_lemma(artist, n):\n",
    "    i = 0\n",
    "    song_tokens = []\n",
    "    songs = (genius.search_artist(artist, max_songs=n, sort='popularity')).songs\n",
    "    s = [song.lyrics for song in songs]\n",
    "    for song in s:\n",
    "        lyrics = song[song.index('\\n')+1:]\n",
    "        tokes = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(lyrics)\n",
    "        tokes = [w.lower() for w in tokes if not w.lower() in nltk.corpus.stopwords.words()]\n",
    "        Lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lem_tokes = []\n",
    "        for toke in tokes:\n",
    "            lem_tokes.append(Lem.lemmatize(toke))\n",
    "        song_tokens.append(lem_tokes)\n",
    "    return song_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "026eafde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine tokens from all songs into one list\n",
    "def combine_tokens(song_tokens):\n",
    "    combined_tokens = []\n",
    "    for song in song_tokens:\n",
    "        for toke in song:\n",
    "            combined_tokens.append(toke)\n",
    "    return combined_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54057e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given list of songs, returns most commonly used words\n",
    "def most_common_lyrics(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    fd = nltk.FreqDist(combined_tokens)\n",
    "    return fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f67eeb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_bigrams(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    bgs = nltk.bigrams(combined_tokens)\n",
    "    fd = nltk.FreqDist(bgs)\n",
    "    return fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94e3bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WRONG BECAUSE SOME ARTISTS HAVE LOTS OF WORDS IN A SONG, SOME HAVE FEW WORDS\n",
    "# given list of song lyrics, return approximate size of vocabulary\n",
    "def vocab_size(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    fd = nltk.FreqDist(combined_tokens)\n",
    "    return len(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "839fc1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given list of artists and number of songs, return most commonly used words/bigrams and size of vocabulary\n",
    "def lyric_anal(artists,n):\n",
    "    print('========Lyric Analysis!========\\n')\n",
    "    for a in artists:\n",
    "        print('Getting lyrics for '+a+'...\\n')\n",
    "        # try...except block to account for random timeouts when pulling lyrics\n",
    "        song_tokens = []\n",
    "        while True:\n",
    "            try:\n",
    "                song_tokens = get_artist_lyrics_lemma(a,n)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        print('Analysis...\\n')\n",
    "        common_words = most_common_lyrics(song_tokens)\n",
    "        common_bigrams = most_common_bigrams(song_tokens)\n",
    "        vocabulary = vocab_size(song_tokens)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s most common words are:\\n')\n",
    "        print(common_words)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s most common bigrams are:\\n')\n",
    "        print(common_bigrams)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s [in progress]:\\n')\n",
    "        print(vocabulary)\n",
    "        print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b8ce0d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Lyric Analysis!========\n",
      "\n",
      "Getting lyrics for Jimmy Hendrix...\n",
      "\n",
      "Searching for songs by Jimmy Hendrix...\n",
      "\n",
      "Couldn't find the lyrics section. Please report this if the song has lyrics.\n",
      "Song URL: https://genius.com/Joe-bonamassa-hey-baby-new-rising-sun-lyrics\n",
      "Done. Found 0 songs.\n",
      "Analysis...\n",
      "\n",
      "------------------------\n",
      "Jimmy Hendrix's most common words are:\n",
      "\n",
      "[]\n",
      "------------------------\n",
      "Jimmy Hendrix's most common bigrams are:\n",
      "\n",
      "[]\n",
      "------------------------\n",
      "Jimmy Hendrix's approximate vocabulary size is:\n",
      "\n",
      "0\n",
      "------------------------\n",
      "Getting lyrics for Led Zeppelin...\n",
      "\n",
      "Searching for songs by Led Zeppelin...\n",
      "\n",
      "Song 1: \"Stairway to Heaven\"\n",
      "Song 2: \"Immigrant Song\"\n",
      "Song 3: \"Kashmir\"\n",
      "Song 4: \"Black Dog\"\n"
     ]
    }
   ],
   "source": [
    "artists = ['Jimmy Hendrix','Led Zeppelin','Pink Floyd']\n",
    "result = lyric_anal(artists,5)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
