{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa30ee77",
   "metadata": {},
   "source": [
    "# Song lyric collection and analysis with lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e5cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lyrics, tokenize by line, word tokenize, analysis\n",
    "# IDEAS : - filter out adlibs\n",
    "# -to check vocab size need to do : # unique words / total words\n",
    "# - need to lemmatize words before removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186c20ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cedge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cedge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import lyricsgenius as lg\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62923bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/Users/cedge/JupyterNotebooks/LyricAnalysis/data/auto_.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2486f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genius = lg.Genius('zleUnA417r4r6kLBco4G748hX7O43uBFJoOFF55Kv2K9YF1fnsKxTbXoIHpzg3fN', skip_non_songs=True,\n",
    "                   excluded_terms=[\"(Remix)\", \"(Live)\"],remove_section_headers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec8345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lyricsgenius to get song lyrics for input artist, return tokenized lyrics\n",
    "def get_artist_lyrics(artist, n):\n",
    "    i = 0\n",
    "    song_tokens = []\n",
    "    songs = (genius.search_artist(artist, max_songs=n, sort='popularity')).songs\n",
    "    s = [song.lyrics for song in songs]\n",
    "    for song in s:\n",
    "        lyrics = song[song.index('\\n')+1:]\n",
    "        tokes = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(lyrics)\n",
    "        tokes = [w.lower() for w in tokes if not w.lower() in nltk.corpus.stopwords.words()]\n",
    "        song_tokens.append(tokes)\n",
    "    return song_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48935cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same function but lemmatizing words\n",
    "def get_artist_lyrics_lemma(artist, n):\n",
    "    i = 0\n",
    "    song_tokens = []\n",
    "    songs = (genius.search_artist(artist, max_songs=n, sort='popularity')).songs\n",
    "    s = [song.lyrics for song in songs]\n",
    "    for song in s:\n",
    "        lyrics = song[song.index('\\n')+1:]\n",
    "        tokes = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(lyrics)\n",
    "        tokes = [w.lower() for w in tokes if not w.lower() in nltk.corpus.stopwords.words()]\n",
    "        Lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lem_tokes = []\n",
    "        for toke in tokes:\n",
    "            lem_tokes.append(Lem.lemmatize(toke))\n",
    "        song_tokens.append(lem_tokes)\n",
    "    return song_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a88216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine tokens from all songs into one list\n",
    "def combine_tokens(song_tokens):\n",
    "    combined_tokens = []\n",
    "    for song in song_tokens:\n",
    "        for toke in song:\n",
    "            combined_tokens.append(toke)\n",
    "    return combined_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b291eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given list of songs, returns most commonly used words\n",
    "def most_common_lyrics(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    fd = nltk.FreqDist(combined_tokens)\n",
    "    return fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8a6ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_bigrams(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    bgs = nltk.bigrams(combined_tokens)\n",
    "    fd = nltk.FreqDist(bgs)\n",
    "    return fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "606bd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WRONG BECAUSE SOME ARTISTS HAVE LOTS OF WORDS IN A SONG, SOME HAVE FEW WORDS\n",
    "# given list of song lyrics, return approximate size of vocabulary\n",
    "def vocab_size(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    fd = nltk.FreqDist(combined_tokens)\n",
    "    return len(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2c7d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given list of artists and number of songs, return most commonly used words/bigrams and size of vocabulary\n",
    "def lyric_anal(artists,n):\n",
    "    print('========Lyric Analysis!========\\n')\n",
    "    for a in artists:\n",
    "        print('Getting lyrics for '+a+'...\\n')\n",
    "        # try...except block to account for random timeouts when pulling lyrics\n",
    "        song_tokens = []\n",
    "        while True:\n",
    "            try:\n",
    "                song_tokens = get_artist_lyrics_lemma(a,n)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        print('Analysis...\\n')\n",
    "        common_words = most_common_lyrics(song_tokens)\n",
    "        common_bigrams = most_common_bigrams(song_tokens)\n",
    "        vocabulary = vocab_size(song_tokens)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s most common words are:\\n')\n",
    "        print(common_words)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s most common bigrams are:\\n')\n",
    "        print(common_bigrams)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s [in progress]:\\n')\n",
    "        print(vocabulary)\n",
    "        print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d92c3db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Lyric Analysis!========\n",
      "\n",
      "Getting lyrics for Jimmi Hendrix...\n",
      "\n",
      "Searching for songs by Jimmi Hendrix...\n",
      "\n",
      "Changing artist name to 'The Jimi Hendrix Experience'\n",
      "Song 1: \"Little Wing\"\n",
      "Song 2: \"Purple Haze\"\n",
      "Song 3: \"All Along the Watchtower\"\n",
      "Song 4: \"Bold as Love\"\n",
      "Song 5: \"Castles Made of Sand\"\n",
      "\n",
      "Reached user-specified song limit (5).\n",
      "Done. Found 5 songs.\n",
      "Analysis...\n",
      "\n",
      "------------------------\n",
      "Jimmi Hendrix's most common words are:\n",
      "\n",
      "[('yeah', 15), ('bold', 7), ('love', 7), ('purple', 6), ('haze', 4), ('know', 4), ('girl', 4), ('help', 4), ('hey', 4), ('life', 4)]\n",
      "------------------------\n",
      "Jimmi Hendrix's most common bigrams are:\n",
      "\n",
      "[(('yeah', 'yeah'), 7), (('bold', 'love'), 6), (('purple', 'haze'), 4)]\n",
      "------------------------\n",
      "Jimmi Hendrix's approximate vocabulary size is:\n",
      "\n",
      "270\n",
      "------------------------\n",
      "Getting lyrics for Led Zeppelin...\n",
      "\n",
      "Searching for songs by Led Zeppelin...\n",
      "\n",
      "Song 1: \"Stairway to Heaven\"\n",
      "Song 2: \"Immigrant Song\"\n",
      "Song 3: \"Kashmir\"\n",
      "Song 4: \"Black Dog\"\n",
      "Song 5: \"Whole Lotta Love\"\n",
      "\n",
      "Reached user-specified song limit (5).\n",
      "Done. Found 5 songs.\n"
     ]
    }
   ],
   "source": [
    "artists = ['Jimmi Hendrix','Led Zeppelin','Pink Floyd']\n",
    "result = lyric_anal(artists,5)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
