{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa30ee77",
   "metadata": {},
   "source": [
    "# Song lyric collection and analysis with lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86e5cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lyrics, tokenize by line, word tokenize, analysis\n",
    "# IDEAS : - filter out adlibs\n",
    "# -to check vocab size need to do : # unique words / total words\n",
    "# - need to lemmatize words before removing stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "186c20ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\cedge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cedge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cedge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import lyricsgenius as lg\n",
    "\n",
    "nltk.download('omw-1.4')    # wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62923bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = open(\"/Users/cedge/JupyterNotebooks/LyricAnalysis/data/auto_.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb2486f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "genius = lg.Genius('zleUnA417r4r6kLBco4G748hX7O43uBFJoOFF55Kv2K9YF1fnsKxTbXoIHpzg3fN', skip_non_songs=True,\n",
    "                   excluded_terms=[\"(Remix)\", \"(Live)\"],remove_section_headers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec8345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lyricsgenius to get song lyrics for input artist, return tokenized lyrics\n",
    "def get_artist_lyrics(artist, n):\n",
    "    print(\"test1\")\n",
    "    i = 0\n",
    "    song_tokens = []\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            songs = (genius.search_artist(artist, max_songs=n, sort='popularity')).songs    \n",
    "            break\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    s = [song.lyrics for song in songs]\n",
    "    for song in s:\n",
    "        lyrics = song[song.index('\\n')+1:]\n",
    "        tokes = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(lyrics)\n",
    "        tokes = [w.lower() for w in tokes if not w.lower() in nltk.corpus.stopwords.words()]\n",
    "        song_tokens.append(tokes)\n",
    "    return song_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d48935cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same function but lemmatizing words\n",
    "def get_artist_lyrics_lemma(artist, n):\n",
    "    i = 0\n",
    "    song_tokens = []\n",
    "    songs = (genius.search_artist(artist, max_songs=n, sort='popularity')).songs\n",
    "    s = [song.lyrics for song in songs]\n",
    "    for song in s:\n",
    "        lyrics = song[song.index('\\n')+1:]\n",
    "        tokes = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(lyrics)\n",
    "        tokes = [w.lower() for w in tokes if not w.lower() in nltk.corpus.stopwords.words()]\n",
    "        Lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lem_tokes = []\n",
    "        for toke in tokes:\n",
    "            lem_tokes.append(Lem.lemmatize(toke))\n",
    "        song_tokens.append(lem_tokes)\n",
    "    return song_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a88216a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine tokens from all songs into one list\n",
    "def combine_tokens(song_tokens):\n",
    "    combined_tokens = []\n",
    "    for song in song_tokens:\n",
    "        for toke in song:\n",
    "            combined_tokens.append(toke)\n",
    "    return combined_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b291eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given list of songs, returns most commonly used words\n",
    "def most_common_lyrics(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    fd = nltk.FreqDist(combined_tokens)\n",
    "    return fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8a6ebd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_bigrams(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    bgs = nltk.bigrams(combined_tokens)\n",
    "    fd = nltk.FreqDist(bgs)\n",
    "    return fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "606bd7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WRONG BECAUSE SOME ARTISTS HAVE LOTS OF WORDS IN A SONG, SOME HAVE FEW WORDS\n",
    "# given list of song lyrics, return approximate size of vocabulary\n",
    "def vocab_size(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    fd = nltk.FreqDist(combined_tokens)\n",
    "    score = fd.B() / fd.N() # num buckets / num outcomes\n",
    "    print('buckets: '+fd.B())\n",
    "    print('outcomes: '+fd.N())\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c7d946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given list of artists and number of songs, return most commonly used words/bigrams and size of vocabulary\n",
    "def lyric_anal(artists,n):\n",
    "    print('========Lyric Analysis!========\\n')\n",
    "    for a in artists:\n",
    "        print('Getting lyrics for '+a+'...\\n')\n",
    "        # try...except block to account for random timeouts when pulling lyrics\n",
    "        song_tokens = []\n",
    "\n",
    "        song_tokens = get_artist_lyrics_lemma(a,n)\n",
    "\n",
    "        print('Analysis...\\n')\n",
    "        common_words = most_common_lyrics(song_tokens)\n",
    "        common_bigrams = most_common_bigrams(song_tokens)\n",
    "        vocabulary = vocab_size(song_tokens)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s most common words are:\\n')\n",
    "        print(common_words)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s most common bigrams are:\\n')\n",
    "        print(common_bigrams)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s [in progress]:\\n')\n",
    "        print(vocabulary)\n",
    "        print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "01c00d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1\n",
      "Searching for songs by Young Thug...\n",
      "\n",
      "Song 1: \"Best Friend\"\n",
      "Song 2: \"The London\"\n",
      "Song 3: \"Check\"\n",
      "\n",
      "Reached user-specified song limit (3).\n",
      "Done. Found 3 songs.\n"
     ]
    }
   ],
   "source": [
    "#lyric_anal(['Young Thug', 'King Von'], 5)\n",
    "song_tokens = get_artist_lyrics('Young Thug', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa3b31e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 363 samples and 786 outcomes>\n",
      "363\n",
      "786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4618320610687023"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_tokens = combine_tokens(song_tokens)\n",
    "fd = nltk.FreqDist(combined_tokens)\n",
    "print(fd)\n",
    "\n",
    "t = 0\n",
    "print(fd.B())\n",
    "print(fd.N())\n",
    "fd.B() / fd.N()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d92c3db",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Lyric Analysis!========\n",
      "\n",
      "Getting lyrics for Young Thug...\n",
      "\n",
      "Searching for songs by Young Thug...\n",
      "\n",
      "Song 1: \"Best Friend\"\n",
      "Song 2: \"The London\"\n",
      "Song 3: \"Check\"\n",
      "Song 4: \"Power\"\n",
      "Song 5: \"With That\"\n",
      "\"Danny Glover (Remix)\" is not valid. Skipping.\n",
      "Song 6: \"Hot\"\n",
      "Song 7: \"2 Bitches (Danny Glover)\"\n",
      "Song 8: \"Stoner\"\n",
      "\"Hot (Remix)\" is not valid. Skipping.\n",
      "Song 9: \"Thief in the Night\"\n",
      "Song 10: \"Relationship\"\n",
      "Song 11: \"Digits\"\n",
      "Song 12: \"Wyclef Jean\"\n",
      "Song 13: \"With Them\"\n",
      "Song 14: \"Guwop\"\n",
      "Song 15: \"Halftime\"\n",
      "Song 16: \"Again\"\n",
      "Song 17: \"Hercules\"\n",
      "Song 18: \"Old English\"\n",
      "Song 19: \"Givenchy\"\n",
      "Song 20: \"Imma Ride (Ridin)\"\n",
      "\n",
      "Reached user-specified song limit (20).\n",
      "Done. Found 20 songs.\n",
      "Analysis...\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"int\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12812\\2746104767.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0martists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Young Thug'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'MF DOOM'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Lil John'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Lil Pump'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlyric_anal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martists\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12812\\4094562873.py\u001b[0m in \u001b[0;36mlyric_anal\u001b[1;34m(artists, n)\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mcommon_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmost_common_lyrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mcommon_bigrams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmost_common_bigrams\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mvocabulary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocab_size\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msong_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'------------------------'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'\\'s most common words are:\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12812\\2548091552.py\u001b[0m in \u001b[0;36mvocab_size\u001b[1;34m(song_tokens)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mfd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFreqDist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcombined_tokens\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# num buckets / num outcomes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'buckets: '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'outcomes: '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
     ]
    }
   ],
   "source": [
    "artists = ['Young Thug', 'MF DOOM', 'Lil John', 'Lil Pump']\n",
    "result = lyric_anal(artists,20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
