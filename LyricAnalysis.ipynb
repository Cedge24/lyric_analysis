{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddade4ba",
   "metadata": {},
   "source": [
    "# Song lyric collection and analysis with lyricsgenius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32772ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lyrics, tokenize by line, word tokenize, analysis\n",
    "# IDEAS : - filter out adlibs\n",
    "# to check vocab size need to do : # unique words / total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f3709b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\cedge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\cedge\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import lyricsgenius as lg\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17a207c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"/Users/cedge/JupyterNotebooks/LyricAnalysis/data/auto_.txt\",\"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c792203f",
   "metadata": {},
   "outputs": [],
   "source": [
    "genius = lg.Genius('zleUnA417r4r6kLBco4G748hX7O43uBFJoOFF55Kv2K9YF1fnsKxTbXoIHpzg3fN', skip_non_songs=True,\n",
    "                   excluded_terms=[\"(Remix)\", \"(Live)\"],remove_section_headers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d04c59e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lyricsgenius to get song lyrics for input artist, return tokenized lyrics\n",
    "def get_artist_lyrics(artist, n):\n",
    "    i = 0\n",
    "    song_tokens = []\n",
    "    songs = (genius.search_artist(artist, max_songs=n, sort='popularity')).songs\n",
    "    s = [song.lyrics for song in songs]\n",
    "    for song in s:\n",
    "        lyrics = song[song.index('\\n')+1:]\n",
    "        tokes = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(lyrics)\n",
    "        tokes = [w.lower() for w in tokes if not w.lower() in nltk.corpus.stopwords.words()]\n",
    "        song_tokens.append(tokes)\n",
    "    return song_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00cc6809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same function but lemmatizing words\n",
    "def get_artist_lyrics_lemma(artist, n):\n",
    "    i = 0\n",
    "    song_tokens = []\n",
    "    songs = (genius.search_artist(artist, max_songs=n, sort='popularity')).songs\n",
    "    s = [song.lyrics for song in songs]\n",
    "    for song in s:\n",
    "        lyrics = song[song.index('\\n')+1:]\n",
    "        tokes = nltk.tokenize.RegexpTokenizer(r'\\w+').tokenize(lyrics)\n",
    "        tokes = [w.lower() for w in tokes if not w.lower() in nltk.corpus.stopwords.words()]\n",
    "        Lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lem_tokes = []\n",
    "        for toke in tokes:\n",
    "            lem_tokes.append(Lem.lemmatize(toke))\n",
    "        song_tokens.append(lem_tokes)\n",
    "    return song_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7464e7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST : young thug\n",
    "#song_tokens_thug = get_artist_lyrics('Young Thug',3)\n",
    "#song_tokens_thug_lemma = get_artist_lyrics_lemma('Young Thug',3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c017576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine tokens from all songs into one list\n",
    "def combine_tokens(song_tokens):\n",
    "    combined_tokens = []\n",
    "    for song in song_tokens:\n",
    "        for toke in song:\n",
    "            combined_tokens.append(toke)\n",
    "    return combined_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4b8fd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given list of songs, returns most commonly used words\n",
    "def most_common_lyrics(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    fd = nltk.FreqDist(combined_tokens)\n",
    "    return fd.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19afb654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_bigrams(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    bgs = nltk.bigrams(combined_tokens)\n",
    "    fd = nltk.FreqDist(bgs)\n",
    "    return fd.most_common(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47f7cee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS WRONG BECAUSE SOME ARTISTS HAVE LOTS OF WORDS IN A SONG, SOME HAVE FEW WORDS\n",
    "# given list of song lyrics, return approximate size of vocabulary\n",
    "def vocab_size(song_tokens):\n",
    "    combined_tokens = combine_tokens(song_tokens)\n",
    "    fd = nltk.FreqDist(combined_tokens)\n",
    "    return len(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a2a3be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given list of artists and number of songs, return most commonly used words/bigrams and size of vocabulary\n",
    "def void lyric_anal(artists,n):\n",
    "    print('========Lyric Analysis!========\\n')\n",
    "    for a in artists:\n",
    "        print('Getting lyrics for '+a+'...\\n')\n",
    "        # try...except block to account for random timeouts when pulling lyrics\n",
    "        song_tokens = []\n",
    "        while True:\n",
    "            try:\n",
    "                song_tokens = get_artist_lyrics_lemma(a,n)\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "        print('Analysis...\\n')\n",
    "        common_words = most_common_lyrics(song_tokens)\n",
    "        common_bigrams = most_common_bigrams(song_tokens)\n",
    "        vocabulary = vocab_size(song_tokens)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s most common words are:\\n')\n",
    "        print(common_words)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s most common bigrams are:\\n')\n",
    "        print(common_bigrams)\n",
    "        print('------------------------')\n",
    "        print(a+'\\'s approximate vocabulary size is:\\n')\n",
    "        print(vocabulary)\n",
    "        print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc3e77c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========Lyric Analysis!========\n",
      "\n",
      "Getting lyrics for Young Thug...\n",
      "\n",
      "Searching for songs by Young Thug...\n",
      "\n",
      "Song 1: \"Best Friend\"\n",
      "Song 2: \"The London\"\n",
      "Song 3: \"Check\"\n",
      "Song 4: \"Power\"\n",
      "Song 5: \"With That\"\n",
      "\"Danny Glover (Remix)\" is not valid. Skipping.\n",
      "Song 6: \"Hot\"\n",
      "Song 7: \"2 Bitches (Danny Glover)\"\n",
      "Song 8: \"Stoner\"\n",
      "\"Hot (Remix)\" is not valid. Skipping.\n",
      "Song 9: \"Thief in the Night\"\n",
      "Song 10: \"Relationship\"\n",
      "Song 11: \"Digits\"\n",
      "Song 12: \"Wyclef Jean\"\n",
      "Song 13: \"With Them\"\n",
      "Song 14: \"Halftime\"\n",
      "Song 15: \"Guwop\"\n",
      "Song 16: \"Again\"\n",
      "Song 17: \"Hercules\"\n",
      "Song 18: \"Old English\"\n",
      "Song 19: \"Imma Ride (Ridin)\"\n",
      "Song 20: \"Givenchy\"\n",
      "Song 21: \"Worth It\"\n",
      "Song 22: \"Floyd Mayweather\"\n",
      "Song 23: \"Anybody\"\n",
      "\"Minnesota (Remix)\" is not valid. Skipping.\n",
      "Song 24: \"Harambe\"\n",
      "Song 25: \"Constantly Hating\"\n",
      "Song 26: \"Take Kare\"\n",
      "Song 27: \"Feel It\"\n",
      "Song 28: \"Bad Bad Bad\"\n",
      "Song 29: \"Family Don’t Matter\"\n",
      "Song 30: \"You Said\"\n",
      "Song 31: \"F Cancer (Boosie)\"\n",
      "Song 32: \"The Blanguage\"\n",
      "\"Old Town Road (Young Thug & Mason Ramsey Remix)\" is not valid. Skipping.\n",
      "Song 33: \"Kanye West\"\n",
      "Song 34: \"Pull Up on a Kid\"\n",
      "Song 35: \"Climax\"\n",
      "Song 36: \"Just Might Be\"\n",
      "Song 37: \"Yea Yea\"\n",
      "Song 38: \"Safe\"\n",
      "Song 39: \"Webbie\"\n",
      "Song 40: \"Just How It Is\"\n",
      "Song 41: \"Hey, I\"\n",
      "Song 42: \"Sin\"\n",
      "Song 43: \"Daddy’s Birthday\"\n",
      "Song 44: \"What’s the Move\"\n",
      "Song 45: \"RiRi\"\n",
      "Song 46: \"Killed Before\"\n",
      "Song 47: \"Bubbly\"\n"
     ]
    }
   ],
   "source": [
    "artists = ['Young Thug','Kanye West','Atmosphere','Comethazine','PlayaPosseStacks']\n",
    "result = lyric_anal(artists,50)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
